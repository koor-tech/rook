<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Rook Ceph Documentation"><meta name=author content="Rook Authors"><link href=https://rook.io/1.7/ceph-disaster-recovery/ rel=canonical><link rel=icon href=https://rook.io/images/favicon_192x192.png><meta name=generator content="mkdocs-1.3.0, mkdocs-material-8.2.5+insiders-4.11.0"><title>Disaster Recovery - Rook Ceph Documentation</title><link rel=stylesheet href=../assets/stylesheets/main.589a02ac.min.css><link rel=stylesheet href=../assets/stylesheets/palette.e6a45f82.min.css><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=rook-blue data-md-color-accent=deep-orange> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#disaster-recovery class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-component=outdated hidden> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Rook Ceph Documentation" class="md-header__button md-logo" aria-label="Rook Ceph Documentation" data-md-component=logo> <img src=https://rook.io/images/rook-logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Rook Ceph Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Disaster Recovery </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=rook-blue data-md-color-accent=deep-orange aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=rook-blue data-md-color-accent=red aria-label="Switch to light mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08z"/></svg> </a> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/rook/rook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Rook Ceph Documentation" class="md-nav__button md-logo" aria-label="Rook Ceph Documentation" data-md-component=logo> <img src=https://rook.io/images/rook-logo.svg alt=logo> </a> Rook Ceph Documentation </label> <div class=md-nav__source> <a href=https://github.com/rook/rook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <span class=md-ellipsis> Rook </span> </a> </li> <li class=md-nav__item> <a href=../async-disaster-recovery/ class=md-nav__link> <span class=md-ellipsis> Failover and Failback </span> </a> </li> <li class=md-nav__item> <a href=../authenticated-registry/ class=md-nav__link> <span class=md-ellipsis> Authenticated Registries </span> </a> </li> <li class=md-nav__item> <a href=../ceph-advanced-configuration/ class=md-nav__link> <span class=md-ellipsis> Advanced Configuration </span> </a> </li> <li class=md-nav__item> <a href=../ceph-block/ class=md-nav__link> <span class=md-ellipsis> Block Storage </span> </a> </li> <li class=md-nav__item> <a href=../ceph-client-crd/ class=md-nav__link> <span class=md-ellipsis> Client CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-cluster-crd/ class=md-nav__link> <span class=md-ellipsis> Cluster CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-common-issues/ class=md-nav__link> <span class=md-ellipsis> Common Issues </span> </a> </li> <li class=md-nav__item> <a href=../ceph-configuration/ class=md-nav__link> <span class=md-ellipsis> Configuration </span> </a> </li> <li class=md-nav__item> <a href=../ceph-csi-drivers/ class=md-nav__link> <span class=md-ellipsis> Ceph CSI </span> </a> </li> <li class=md-nav__item> <a href=../ceph-csi-snapshot/ class=md-nav__link> <span class=md-ellipsis> Snapshots </span> </a> </li> <li class=md-nav__item> <a href=../ceph-csi-troubleshooting/ class=md-nav__link> <span class=md-ellipsis> CSI Common Issues </span> </a> </li> <li class=md-nav__item> <a href=../ceph-csi-volume-clone/ class=md-nav__link> <span class=md-ellipsis> Volume clone </span> </a> </li> <li class=md-nav__item> <a href=../ceph-dashboard/ class=md-nav__link> <span class=md-ellipsis> Ceph Dashboard </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Disaster Recovery </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Disaster Recovery </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#restoring-mon-quorum class=md-nav__link> Restoring Mon Quorum </a> <nav class=md-nav aria-label="Restoring Mon Quorum"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#stop-the-operator class=md-nav__link> Stop the operator </a> </li> <li class=md-nav__item> <a href=#inject-a-new-monmap class=md-nav__link> Inject a new monmap </a> </li> <li class=md-nav__item> <a href=#edit-the-rook-configmaps class=md-nav__link> Edit the Rook configmaps </a> </li> <li class=md-nav__item> <a href=#restart-the-mon class=md-nav__link> Restart the mon </a> </li> <li class=md-nav__item> <a href=#restart-the-operator class=md-nav__link> Restart the operator </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#restoring-crds-after-deletion class=md-nav__link> Restoring CRDs After Deletion </a> </li> <li class=md-nav__item> <a href=#adopt-an-existing-rook-ceph-cluster-into-a-new-kubernetes-cluster class=md-nav__link> Adopt an existing Rook Ceph cluster into a new Kubernetes cluster </a> <nav class=md-nav aria-label="Adopt an existing Rook Ceph cluster into a new Kubernetes cluster"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> Prerequisites </a> </li> <li class=md-nav__item> <a href=#overview-for-steps-below class=md-nav__link> Overview for Steps below </a> </li> <li class=md-nav__item> <a href=#steps class=md-nav__link> Steps </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#backing-up-and-restoring-a-cluster-based-on-pvcs-into-a-new-kubernetes-cluster class=md-nav__link> Backing up and restoring a cluster based on PVCs into a new Kubernetes cluster </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../ceph-examples/ class=md-nav__link> <span class=md-ellipsis> Examples </span> </a> </li> <li class=md-nav__item> <a href=../ceph-filesystem-crd/ class=md-nav__link> <span class=md-ellipsis> Shared Filesystem CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-filesystem/ class=md-nav__link> <span class=md-ellipsis> Shared Filesystem </span> </a> </li> <li class=md-nav__item> <a href=../ceph-fs-mirror-crd/ class=md-nav__link> <span class=md-ellipsis> Filesystem Mirror CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-fs-subvolumegroup/ class=md-nav__link> <span class=md-ellipsis> SubVolume Group CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-kms/ class=md-nav__link> <span class=md-ellipsis> Key Management System </span> </a> </li> <li class=md-nav__item> <a href=../ceph-mon-health/ class=md-nav__link> <span class=md-ellipsis> Monitor Health </span> </a> </li> <li class=md-nav__item> <a href=../ceph-monitoring/ class=md-nav__link> <span class=md-ellipsis> Prometheus Monitoring </span> </a> </li> <li class=md-nav__item> <a href=../ceph-nfs-crd/ class=md-nav__link> <span class=md-ellipsis> NFS CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-object-bucket-claim/ class=md-nav__link> <span class=md-ellipsis> Object Bucket Claim </span> </a> </li> <li class=md-nav__item> <a href=../ceph-object-bucket-notifications/ class=md-nav__link> <span class=md-ellipsis> Bucket Notifications </span> </a> </li> <li class=md-nav__item> <a href=../ceph-object-multisite-crd/ class=md-nav__link> <span class=md-ellipsis> Object Multisite CRDs </span> </a> </li> <li class=md-nav__item> <a href=../ceph-object-multisite/ class=md-nav__link> <span class=md-ellipsis> Object Multisite </span> </a> </li> <li class=md-nav__item> <a href=../ceph-object-store-crd/ class=md-nav__link> <span class=md-ellipsis> Object Store CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-object-store-user-crd/ class=md-nav__link> <span class=md-ellipsis> Object Store User CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-object/ class=md-nav__link> <span class=md-ellipsis> Object Storage </span> </a> </li> <li class=md-nav__item> <a href=../ceph-openshift-issues/ class=md-nav__link> <span class=md-ellipsis> OpenShift Common Issues </span> </a> </li> <li class=md-nav__item> <a href=../ceph-openshift/ class=md-nav__link> <span class=md-ellipsis> OpenShift </span> </a> </li> <li class=md-nav__item> <a href=../ceph-osd-mgmt/ class=md-nav__link> <span class=md-ellipsis> OSD Management </span> </a> </li> <li class=md-nav__item> <a href=../ceph-pool-crd/ class=md-nav__link> <span class=md-ellipsis> Block Pool CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-pool-radosnamespace/ class=md-nav__link> <span class=md-ellipsis> RADOS Namespace CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-rbd-mirror-crd/ class=md-nav__link> <span class=md-ellipsis> RBD Mirror CRD </span> </a> </li> <li class=md-nav__item> <a href=../ceph-storage/ class=md-nav__link> <span class=md-ellipsis> Ceph Storage </span> </a> </li> <li class=md-nav__item> <a href=../ceph-teardown/ class=md-nav__link> <span class=md-ellipsis> Cleanup </span> </a> </li> <li class=md-nav__item> <a href=../ceph-toolbox/ class=md-nav__link> <span class=md-ellipsis> Toolbox </span> </a> </li> <li class=md-nav__item> <a href=../ceph-tools/ class=md-nav__link> <span class=md-ellipsis> Ceph Tools </span> </a> </li> <li class=md-nav__item> <a href=../ceph-upgrade/ class=md-nav__link> <span class=md-ellipsis> Upgrades </span> </a> </li> <li class=md-nav__item> <a href=../common-issues/ class=md-nav__link> <span class=md-ellipsis> Common Issues </span> </a> </li> <li class=md-nav__item> <a href=../development-environment/ class=md-nav__link> <span class=md-ellipsis> Developer Environment </span> </a> </li> <li class=md-nav__item> <a href=../development-flow/ class=md-nav__link> <span class=md-ellipsis> Contributing </span> </a> </li> <li class=md-nav__item> <a href=../direct-tools/ class=md-nav__link> <span class=md-ellipsis> Direct Tools </span> </a> </li> <li class=md-nav__item> <a href=../helm-ceph-cluster/ class=md-nav__link> <span class=md-ellipsis> Ceph Cluster </span> </a> </li> <li class=md-nav__item> <a href=../helm-operator/ class=md-nav__link> <span class=md-ellipsis> Ceph Operator </span> </a> </li> <li class=md-nav__item> <a href=../helm/ class=md-nav__link> <span class=md-ellipsis> Helm Charts </span> </a> </li> <li class=md-nav__item> <a href=../pod-security-policies/ class=md-nav__link> <span class=md-ellipsis> Pod Security Policies </span> </a> </li> <li class=md-nav__item> <a href=../pre-reqs/ class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=../quickstart/ class=md-nav__link> <span class=md-ellipsis> Quickstart </span> </a> </li> <li class=md-nav__item> <a href=../rbd-mirroring/ class=md-nav__link> <span class=md-ellipsis> RBD Mirroring </span> </a> </li> <li class=md-nav__item> <a href=../storage-providers/ class=md-nav__link> <span class=md-ellipsis> Storage Providers </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#restoring-mon-quorum class=md-nav__link> Restoring Mon Quorum </a> <nav class=md-nav aria-label="Restoring Mon Quorum"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#stop-the-operator class=md-nav__link> Stop the operator </a> </li> <li class=md-nav__item> <a href=#inject-a-new-monmap class=md-nav__link> Inject a new monmap </a> </li> <li class=md-nav__item> <a href=#edit-the-rook-configmaps class=md-nav__link> Edit the Rook configmaps </a> </li> <li class=md-nav__item> <a href=#restart-the-mon class=md-nav__link> Restart the mon </a> </li> <li class=md-nav__item> <a href=#restart-the-operator class=md-nav__link> Restart the operator </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#restoring-crds-after-deletion class=md-nav__link> Restoring CRDs After Deletion </a> </li> <li class=md-nav__item> <a href=#adopt-an-existing-rook-ceph-cluster-into-a-new-kubernetes-cluster class=md-nav__link> Adopt an existing Rook Ceph cluster into a new Kubernetes cluster </a> <nav class=md-nav aria-label="Adopt an existing Rook Ceph cluster into a new Kubernetes cluster"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> Prerequisites </a> </li> <li class=md-nav__item> <a href=#overview-for-steps-below class=md-nav__link> Overview for Steps below </a> </li> <li class=md-nav__item> <a href=#steps class=md-nav__link> Steps </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#backing-up-and-restoring-a-cluster-based-on-pvcs-into-a-new-kubernetes-cluster class=md-nav__link> Backing up and restoring a cluster based on PVCs into a new Kubernetes cluster </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/rook/rook/edit/master/Documentation/ceph-disaster-recovery.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=disaster-recovery>Disaster Recovery<a class=headerlink href=#disaster-recovery title="Permanent link">&para;</a></h1> <p>Under extenuating circumstances, steps may be necessary to recover the cluster health. There are several types of recovery addressed in this document: * <a href=#restoring-mon-quorum>Restoring Mon Quorum</a> * <a href=#restoring-crds-after-deletion>Restoring CRDs After Deletion</a> * <a href=#adopt-an-existing-rook-ceph-cluster-into-a-new-kubernetes-cluster>Adopt an existing Rook Ceph cluster into a new Kubernetes cluster</a> * <a href=#backing-up-and-restoring-a-cluster-based-on-pvcs-into-a-new-kubernetes-cluster>Backing up and restoring a cluster based on PVCs into a new Kubernetes cluster</a></p> <h2 id=restoring-mon-quorum>Restoring Mon Quorum<a class=headerlink href=#restoring-mon-quorum title="Permanent link">&para;</a></h2> <p>Under extenuating circumstances, the mons may lose quorum. If the mons cannot form quorum again,<br> there is a manual procedure to get the quorum going again. The only requirement is that at least one mon<br> is still healthy. The following steps will remove the unhealthy<br> mons from quorum and allow you to form a quorum again with a single mon, then grow the quorum back to the original size.</p> <p>For example, if you have three mons and lose quorum, you will need to remove the two bad mons from quorum, notify the good mon<br> that it is the only mon in quorum, and then restart the good mon.</p> <h3 id=stop-the-operator>Stop the operator<a class=headerlink href=#stop-the-operator title="Permanent link">&para;</a></h3> <p>First, stop the operator so it will not try to failover the mons while we are modifying the monmap</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=0</span>
</code></pre></div> </td></tr></table> <h3 id=inject-a-new-monmap>Inject a new monmap<a class=headerlink href=#inject-a-new-monmap title="Permanent link">&para;</a></h3> <blockquote> <p><strong>WARNING</strong>: Injecting a monmap must be done very carefully. If run incorrectly, your cluster could be permanently destroyed.</p> </blockquote> <p>The Ceph monmap keeps track of the mon quorum. We will update the monmap to only contain the healthy mon.<br> In this example, the healthy mon is <code>rook-ceph-mon-b</code>, while the unhealthy mons are <code>rook-ceph-mon-a</code> and <code>rook-ceph-mon-c</code>.</p> <p>Take a backup of the current <code>rook-ceph-mon-b</code> Deployment:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>kubectl -n rook-ceph get deployment rook-ceph-mon-b -o yaml &gt; rook-ceph-mon-b-deployment.yaml</span>
</code></pre></div> </td></tr></table> <p>Open the file and copy the <code>command</code> and <code>args</code> from the <code>mon</code> container (see <code>containers</code> list). This is needed for the monmap changes.<br> Cleanup the copied <code>command</code> and <code>args</code> fields to form a pastable command.<br> Example:</p> <p>The following parts of the <code>mon</code> container:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class="p p-Indicator">[</span><span class=nv>...</span><span class="p p-Indicator">]</span><span class=w></span>
<span class=w>  </span><span class=nt>containers</span><span class=p>:</span><span class=w></span>
<span class=w>  </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>args</span><span class=p>:</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--fsid=41a537f2-f282-428e-989f-a9e07be32e47</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--keyring=/etc/ceph/keyring-store/keyring</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--log-to-stderr=true</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--err-to-stderr=true</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--mon-cluster-log-to-stderr=true</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class=s>&#39;--log-stderr-prefix=debug</span><span class=nv> </span><span class=s>&#39;</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--default-log-to-file=false</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--default-mon-cluster-log-to-file=false</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--mon-host=$(ROOK_CEPH_MON_HOST)</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--mon-initial-members=$(ROOK_CEPH_MON_INITIAL_MEMBERS)</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--id=b</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--setuser=ceph</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--setgroup=ceph</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--foreground</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--public-addr=10.100.13.242</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--setuser-match-path=/var/lib/ceph/mon/ceph-b/store.db</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">--public-bind-addr=$(ROOK_POD_IP)</span><span class=w></span>
<span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">ceph-mon</span><span class=w></span>
<span class="p p-Indicator">[</span><span class=nv>...</span><span class="p p-Indicator">]</span><span class=w></span>
</code></pre></div> </td></tr></table> <p>Should be made into a command like this: (<strong>do not copy the example command!</strong>)</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>ceph-mon \</span>
<span class=go>    --fsid=41a537f2-f282-428e-989f-a9e07be32e47 \</span>
<span class=go>    --keyring=/etc/ceph/keyring-store/keyring \</span>
<span class=go>    --log-to-stderr=true \</span>
<span class=go>    --err-to-stderr=true \</span>
<span class=go>    --mon-cluster-log-to-stderr=true \</span>
<span class=go>    --log-stderr-prefix=debug \</span>
<span class=go>    --default-log-to-file=false \</span>
<span class=go>    --default-mon-cluster-log-to-file=false \</span>
<span class=go>    --mon-host=$ROOK_CEPH_MON_HOST \</span>
<span class=go>    --mon-initial-members=$ROOK_CEPH_MON_INITIAL_MEMBERS \</span>
<span class=go>    --id=b \</span>
<span class=go>    --setuser=ceph \</span>
<span class=go>    --setgroup=ceph \</span>
<span class=go>    --foreground \</span>
<span class=go>    --public-addr=10.100.13.242 \</span>
<span class=go>    --setuser-match-path=/var/lib/ceph/mon/ceph-b/store.db \</span>
<span class=go>    --public-bind-addr=$ROOK_POD_IP</span>
</code></pre></div> </td></tr></table> <p>(be sure to remove the single quotes around the <code>--log-stderr-prefix</code> flag and the parenthesis around the variables being passed ROOK_CEPH_MON_HOST, ROOK_CEPH_MON_INITIAL_MEMBERS and ROOK_POD_IP )</p> <p>Patch the <code>rook-ceph-mon-b</code> Deployment to stop this mon working without deleting the mon pod:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>kubectl -n rook-ceph patch deployment rook-ceph-mon-b  --type=&#39;json&#39; -p &#39;[{&quot;op&quot;:&quot;remove&quot;, &quot;path&quot;:&quot;/spec/template/spec/containers/0/livenessProbe&quot;}]&#39;</span>

<span class=go>kubectl -n rook-ceph patch deployment rook-ceph-mon-b -p &#39;{&quot;spec&quot;: {&quot;template&quot;: {&quot;spec&quot;: {&quot;containers&quot;: [{&quot;name&quot;: &quot;mon&quot;, &quot;command&quot;: [&quot;sleep&quot;, &quot;infinity&quot;], &quot;args&quot;: []}]}}}}&#39;</span>
</code></pre></div> </td></tr></table> <p>Connect to the pod of a healthy mon and run the following commands.</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>kubectl -n rook-ceph exec -it &lt;mon-pod&gt; bash</span>
</code></pre></div> </td></tr></table> <blockquote> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span>
<span class=normal>26</span>
<span class=normal>27</span>
<span class=normal>28</span>
<span class=normal>29</span>
<span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span>
<span class=normal>34</span>
<span class=normal>35</span>
<span class=normal>36</span>
<span class=normal>37</span>
<span class=normal>38</span>
<span class=normal>39</span>
<span class=normal>40</span>
<span class=normal>41</span>
<span class=normal>42</span>
<span class=normal>43</span>
<span class=normal>44</span>
<span class=normal>45</span>
<span class=normal>46</span>
<span class=normal>47</span>
<span class=normal>48</span>
<span class=normal>49</span>
<span class=normal>50</span>
<span class=normal>51</span>
<span class=normal>52</span>
<span class=normal>53</span>
<span class=normal>54</span>
<span class=normal>55</span>
<span class=normal>56</span>
<span class=normal>57</span>
<span class=normal>58</span>
<span class=normal>59</span>
<span class=normal>60</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code># set a few simple variables
cluster_namespace=rook-ceph
good_mon_id=b
monmap_path=/tmp/monmap

# extract the monmap to a file, by pasting the ceph mon command
# from the good mon deployment and adding the
# `--extract-monmap=${monmap_path}` flag
ceph-mon \
    --fsid=41a537f2-f282-428e-989f-a9e07be32e47 \
    --keyring=/etc/ceph/keyring-store/keyring \
    --log-to-stderr=true \
    --err-to-stderr=true \
    --mon-cluster-log-to-stderr=true \
    --log-stderr-prefix=debug \
    --default-log-to-file=false \
    --default-mon-cluster-log-to-file=false \
    --mon-host=$ROOK_CEPH_MON_HOST \
    --mon-initial-members=$ROOK_CEPH_MON_INITIAL_MEMBERS \
    --id=b \
    --setuser=ceph \
    --setgroup=ceph \
    --foreground \
    --public-addr=10.100.13.242 \
    --setuser-match-path=/var/lib/ceph/mon/ceph-b/store.db \
    --public-bind-addr=$ROOK_POD_IP \
    --extract-monmap=${monmap_path}

# review the contents of the monmap
monmaptool --print /tmp/monmap

# remove the bad mon(s) from the monmap
monmaptool ${monmap_path} --rm &lt;bad_mon&gt;

# in this example we remove mon0 and mon2:
monmaptool ${monmap_path} --rm a
monmaptool ${monmap_path} --rm c

# inject the modified monmap into the good mon, by pasting
# the ceph mon command and adding the
# `--inject-monmap=${monmap_path}` flag, like this
ceph-mon \
    --fsid=41a537f2-f282-428e-989f-a9e07be32e47 \
    --keyring=/etc/ceph/keyring-store/keyring \
    --log-to-stderr=true \
    --err-to-stderr=true \
    --mon-cluster-log-to-stderr=true \
    --log-stderr-prefix=debug \
    --default-log-to-file=false \
    --default-mon-cluster-log-to-file=false \
    --mon-host=$ROOK_CEPH_MON_HOST \
    --mon-initial-members=$ROOK_CEPH_MON_INITIAL_MEMBERS \
    --id=b \
    --setuser=ceph \
    --setgroup=ceph \
    --foreground \
    --public-addr=10.100.13.242 \
    --setuser-match-path=/var/lib/ceph/mon/ceph-b/store.db \
    --public-bind-addr=$ROOK_POD_IP \
    --inject-monmap=${monmap_path}
</code></pre></div> </td></tr></table> </blockquote> <p>Exit the shell to continue.</p> <h3 id=edit-the-rook-configmaps>Edit the Rook configmaps<a class=headerlink href=#edit-the-rook-configmaps title="Permanent link">&para;</a></h3> <p>Edit the configmap that the operator uses to track the mons.</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>kubectl -n rook-ceph edit configmap rook-ceph-mon-endpoints</span>
</code></pre></div> </td></tr></table> <p>In the <code>data</code> element you will see three mons such as the following (or more depending on your <code>moncount</code>):</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=nt>data</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">a=10.100.35.200:6789;b=10.100.13.242:6789;c=10.100.35.12:6789</span><span class=w></span>
</code></pre></div> </td></tr></table> <p>Delete the bad mons from the list, for example to end up with a single good mon:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=nt>data</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">b=10.100.13.242:6789</span><span class=w></span>
</code></pre></div> </td></tr></table> <p>Save the file and exit.</p> <p>Now we need to adapt a Secret which is used for the mons and other components.<br> The following <code>kubectl patch</code> command is an easy way to do that. In the end it patches the <code>rook-ceph-config</code> secret and updates the two key/value pairs <code>mon_host</code> and <code>mon_initial_members</code>.</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>mon_host=$(kubectl -n rook-ceph get svc rook-ceph-mon-b -o jsonpath=&#39;{.spec.clusterIP}&#39;)</span>
<span class=go>kubectl -n rook-ceph patch secret rook-ceph-config -p &#39;{&quot;stringData&quot;: {&quot;mon_host&quot;: &quot;[v2:&#39;&quot;${mon_host}&quot;&#39;:3300,v1:&#39;&quot;${mon_host}&quot;&#39;:6789]&quot;, &quot;mon_initial_members&quot;: &quot;&#39;&quot;${good_mon_id}&quot;&#39;&quot;}}&#39;</span>
</code></pre></div> </td></tr></table> <blockquote> <p><strong>NOTE</strong>: If you are using <code>hostNetwork: true</code>, you need to replace the <code>mon_host</code> var with the node IP the mon is pinned to (<code>nodeSelector</code>). This is because there is no <code>rook-ceph-mon-*</code> service created in that "mode".</p> </blockquote> <h3 id=restart-the-mon>Restart the mon<a class=headerlink href=#restart-the-mon title="Permanent link">&para;</a></h3> <p>You will need to "restart" the good mon pod with the original <code>ceph-mon</code> command to pick up the changes. For this run <code>kubectl replace</code> on the backup of the mon deployment yaml:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>kubectl replace --force -f rook-ceph-mon-b-deployment.yaml</span>
</code></pre></div> </td></tr></table> <blockquote> <p><strong>NOTE</strong>: Option <code>--force</code> will delete the deployment and create a new one</p> </blockquote> <p>Start the rook <a href=/Documentation/ceph-toolbox.md>toolbox</a> and verify the status of the cluster.</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>ceph -s</span>
</code></pre></div> </td></tr></table> <p>The status should show one mon in quorum. If the status looks good, your cluster should be healthy again.</p> <h3 id=restart-the-operator>Restart the operator<a class=headerlink href=#restart-the-operator title="Permanent link">&para;</a></h3> <p>Start the rook operator again to resume monitoring the health of the cluster.<br> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=gp># </span>create the operator. it is safe to ignore the errors that a number of resources already exist.
<span class=go>kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=1</span>
</code></pre></div> </td></tr></table></p> <p>The operator will automatically add more mons to increase the quorum size again, depending on the <code>mon.count</code>.</p> <h2 id=restoring-crds-after-deletion>Restoring CRDs After Deletion<a class=headerlink href=#restoring-crds-after-deletion title="Permanent link">&para;</a></h2> <p>When the Rook CRDs are deleted, the Rook operator will respond to the deletion event to attempt to clean up the cluster resources.<br> If any data appears present in the cluster, Rook will refuse to allow the resources to be deleted since the operator will<br> refuse to remove the finalizer on the CRs until the underlying data is deleted. For more details, see the<br> <a href=https://github.com/rook/rook/blob/master/design/ceph/resource-dependencies.md>dependency design doc</a>.</p> <p>While it is good that the CRs will not be deleted and the underlying Ceph data and daemons continue to be<br> available, the CRs will be stuck indefinitely in a <code>Deleting</code> state in which the operator will not<br> continue to ensure cluster health. Upgrades will be blocked, further updates to the CRs are prevented, and so on.<br> Since Kubernetes does not allow undeleting resources, the following procedure will allow you to restore<br> the CRs to their prior state without even necessarily suffering cluster downtime.</p> <ol> <li>Scale down the operator</li> </ol> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>kubectl -n rook-ceph scale --replicas=0 deploy/rook-ceph-operator</span>
</code></pre></div> </td></tr></table> <ol> <li>Backup all Rook CRs and critical metadata</li> </ol> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span>
<span class=normal>6</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=gp># </span>Store the CephCluster CR settings. Also, save other Rook CRs that are <span class=k>in</span> terminating state.
<span class=go>kubectl -n rook-ceph get cephcluster rook-ceph -o yaml &gt; cluster.yaml</span>

<span class=gp># </span>Backup critical secrets and configmaps <span class=k>in</span> <span class=k>case</span> something goes wrong later <span class=k>in</span> the procedure
<span class=go>kubectl -n rook-ceph get secret -o yaml &gt; secrets.yaml</span>
<span class=go>kubectl -n rook-ceph get configmap -o yaml &gt; configmaps.yaml</span>
</code></pre></div> </td></tr></table> <ol> <li>Remove the owner references from all critical Rook resources that were referencing the CephCluster CR.<br> The critical resources include:</li> <li>Secrets: <code>rook-ceph-admin-keyring</code>, <code>rook-ceph-config</code>, <code>rook-ceph-mon</code>, <code>rook-ceph-mons-keyring</code></li> <li>ConfigMap: <code>rook-ceph-mon-endpoints</code></li> <li>Services: <code>rook-ceph-mon-*</code>, <code>rook-ceph-mgr-*</code></li> <li>Deployments: <code>rook-ceph-mon-*</code>, <code>rook-ceph-osd-*</code>, <code>rook-ceph-mgr-*</code></li> <li>PVCs (if applicable): <code>rook-ceph-mon-*</code> and the OSD PVCs (named <code>&lt;deviceset&gt;-*</code>, for example <code>set1-data-*</code>)</li> </ol> <p>For example, remove this entire block from each resource:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span>
<span class=normal>6</span>
<span class=normal>7</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=nt>ownerReferences</span><span class=p>:</span><span class=w></span>
<span class="p p-Indicator">-</span><span class=w> </span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">ceph.rook.io/v1</span><span class=w></span>
<span class=w>    </span><span class="l l-Scalar l-Scalar-Plain">blockOwnerDeletion</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class=w></span>
<span class=w>    </span><span class="l l-Scalar l-Scalar-Plain">controller</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class=w></span>
<span class=w>    </span><span class="l l-Scalar l-Scalar-Plain">kind</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">CephCluster</span><span class=w></span>
<span class=w>    </span><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">rook-ceph</span><span class=w></span>
<span class=w>    </span><span class="l l-Scalar l-Scalar-Plain">uid</span><span class="p p-Indicator">:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">&lt;uid&gt;</span><span class=w></span>
</code></pre></div> </td></tr></table> <ol> <li><strong>After confirming all critical resources have had the owner reference to the CephCluster CR removed</strong>, now<br> we allow the cluster CR to be deleted. Remove the finalizer by editing the CephCluster CR.</li> </ol> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>kubectl -n rook-ceph edit cephcluster</span>
</code></pre></div> </td></tr></table> <p>For example, remove the following from the CR metadata:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=w>    </span><span class=nt>finalizers</span><span class=p>:</span><span class=w></span>
<span class=w>    </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">cephcluster.ceph.rook.io</span><span class=w></span>
</code></pre></div> </td></tr></table> <p>After the finalizer is removed, the CR will be immediately deleted. If all owner references were properly removed,<br> all ceph daemons will continue running and there will be no downtime.</p> <ol> <li>Create the CephCluster CR with the same settings as previously</li> </ol> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=c1># Use the same cluster settings as exported above in step 2.</span>
kubectl create -f cluster.yaml
</code></pre></div> </td></tr></table> <ol> <li>If there are other CRs in terminating state such as CephBlockPools, CephObjectStores, or CephFilesystems,<br> follow the above steps as well for those CRs:</li> <li>Backup the CR</li> <li>Remove the finalizer and confirm the CR is deleted (the underlying Ceph resources will be preserved)</li> <li> <p>Create the CR again</p> </li> <li> <p>Scale up the operator</p> </li> </ol> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code>kubectl -n rook-ceph scale --replicas<span class=o>=</span><span class=m>1</span> deploy/rook-ceph-operator
</code></pre></div> </td></tr></table> <p>Watch the operator log to confirm that the reconcile completes successfully.</p> <h2 id=adopt-an-existing-rook-ceph-cluster-into-a-new-kubernetes-cluster>Adopt an existing Rook Ceph cluster into a new Kubernetes cluster<a class=headerlink href=#adopt-an-existing-rook-ceph-cluster-into-a-new-kubernetes-cluster title="Permanent link">&para;</a></h2> <p>Situations this section can help resolve:</p> <ol> <li>The Kubernetes environment underlying a running Rook Ceph cluster failed catastrophically, requiring a new Kubernetes environment in which the user wishes to recover the previous Rook Ceph cluster.</li> <li>The user wishes to migrate their existing Rook Ceph cluster to a new Kubernetes environment, and downtime can be tolerated.</li> </ol> <h3 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">&para;</a></h3> <ol> <li>A working Kubernetes cluster to which we will migrate the previous Rook Ceph cluster.</li> <li>At least one Ceph mon db is in quorum, and sufficient number of Ceph OSD is <code>up</code> and <code>in</code> before disaster.</li> <li>The previous Rook Ceph cluster is not running.</li> </ol> <h3 id=overview-for-steps-below>Overview for Steps below<a class=headerlink href=#overview-for-steps-below title="Permanent link">&para;</a></h3> <ol> <li>Start a new and clean Rook Ceph cluster, with old <code>CephCluster</code> <code>CephBlockPool</code> <code>CephFilesystem</code> <code>CephNFS</code> <code>CephObjectStore</code>.</li> <li>Shut the new cluster down when it has been created successfully.</li> <li>Replace ceph-mon data with that of the old cluster.</li> <li>Replace <code>fsid</code> in <code>secrets/rook-ceph-mon</code> with that of the old one.</li> <li>Fix monmap in ceph-mon db.</li> <li>Fix ceph mon auth key.</li> <li>Disable auth.</li> <li>Start the new cluster, watch it resurrect.</li> <li>Fix admin auth key, and enable auth.</li> <li>Restart cluster for the final time.</li> </ol> <h3 id=steps>Steps<a class=headerlink href=#steps title="Permanent link">&para;</a></h3> <p>Assuming <code>dataHostPathData</code> is <code>/var/lib/rook</code>, and the <code>CephCluster</code> trying to adopt is named <code>rook-ceph</code>.</p> <ol> <li>Make sure the old Kubernetes cluster is completely torn down and the new Kubernetes cluster is up and running without Rook Ceph.</li> <li>Backup <code>/var/lib/rook</code> in all the Rook Ceph nodes to a different directory. Backups will be used later.</li> <li>Pick a <code>/var/lib/rook/rook-ceph/rook-ceph.config</code> from any previous Rook Ceph node and save the old cluster <code>fsid</code> from its content.</li> <li>Remove <code>/var/lib/rook</code> from all the Rook Ceph nodes.</li> <li>Add identical <code>CephCluster</code> descriptor to the new Kubernetes cluster, especially identical <code>spec.storage.config</code> and <code>spec.storage.nodes</code>, except <code>mon.count</code>, which should be set to <code>1</code>.</li> <li>Add identical <code>CephFilesystem</code> <code>CephBlockPool</code> <code>CephNFS</code> <code>CephObjectStore</code> descriptors (if any) to the new Kubernetes cluster.</li> <li>Install Rook Ceph in the new Kubernetes cluster.</li> <li>Watch the operator logs with <code>kubectl -n rook-ceph logs -f rook-ceph-operator-xxxxxxx</code>, and wait until the orchestration has settled.</li> <li><strong>STATE</strong>: Now the cluster will have <code>rook-ceph-mon-a</code>, <code>rook-ceph-mgr-a</code>, and all the auxiliary pods up and running, and zero (hopefully) <code>rook-ceph-osd-ID-xxxxxx</code> running. <code>ceph -s</code> output should report 1 mon, 1 mgr running, and all of the OSDs down, all PGs are in <code>unknown</code> state. Rook should not start any OSD daemon since all devices belongs to the old cluster (which have a different <code>fsid</code>).</li> <li> <p>Run <code>kubectl -n rook-ceph exec -it rook-ceph-mon-a-xxxxxxxx bash</code> to enter the <code>rook-ceph-mon-a</code> pod,</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code>mon-a# cat /etc/ceph/keyring-store/keyring  <span class=c1># save this keyring content for later use</span>
mon-a# <span class=nb>exit</span>
</code></pre></div> </td></tr></table> </li> <li> <p>Stop the Rook operator by running <code>kubectl -n rook-ceph edit deploy/rook-ceph-operator</code> and set <code>replicas</code> to <code>0</code>.</p> </li> <li>Stop cluster daemons by running <code>kubectl -n rook-ceph delete deploy/X</code> where X is every deployment in namespace <code>rook-ceph</code>, except <code>rook-ceph-operator</code> and <code>rook-ceph-tools</code>.</li> <li> <p>Save the <code>rook-ceph-mon-a</code> address with <code>kubectl -n rook-ceph get cm/rook-ceph-mon-endpoints -o yaml</code> in the new Kubernetes cluster for later use.</p> </li> <li> <p>SSH to the host where <code>rook-ceph-mon-a</code> in the new Kubernetes cluster resides.</p> <ol> <li>Remove <code>/var/lib/rook/mon-a</code></li> <li>Pick a healthy <code>rook-ceph-mon-ID</code> directory (<code>/var/lib/rook/mon-ID</code>) in the previous backup, copy to <code>/var/lib/rook/mon-a</code>. <code>ID</code> is any healthy mon node ID of the old cluster.</li> <li>Replace <code>/var/lib/rook/mon-a/keyring</code> with the saved keyring, preserving only the <code>[mon.]</code> section, remove <code>[client.admin]</code> section.</li> <li> <p>Run <code>docker run -it --rm -v /var/lib/rook:/var/lib/rook ceph/ceph:v14.2.1-20190430 bash</code>. The Docker image tag should match the Ceph version used in the Rook cluster. The <code>/etc/ceph/ceph.conf</code> file needs to exist for <code>ceph-mon</code> to work.</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code>touch /etc/ceph/ceph.conf
<span class=nb>cd</span> /var/lib/rook
ceph-mon --extract-monmap monmap --mon-data ./mon-a/data  <span class=c1># Extract monmap from old ceph-mon db and save as monmap</span>
monmaptool --print monmap  <span class=c1># Print the monmap content, which reflects the old cluster ceph-mon configuration.</span>
monmaptool --rm a monmap  <span class=c1># Delete `a` from monmap.</span>
monmaptool --rm b monmap  <span class=c1># Repeat, and delete `b` from monmap.</span>
monmaptool --rm c monmap  <span class=c1># Repeat this pattern until all the old ceph-mons are removed</span>
monmaptool --rm d monmap
monmaptool --rm e monmap
monmaptool --addv a <span class=o>[</span>v2:10.77.2.216:3300,v1:10.77.2.216:6789<span class=o>]</span> monmap   <span class=c1># Replace it with the rook-ceph-mon-a address you got from previous command.</span>
ceph-mon --inject-monmap monmap --mon-data ./mon-a/data  <span class=c1># Replace monmap in ceph-mon db with our modified version.</span>
rm monmap
<span class=nb>exit</span>
</code></pre></div> </td></tr></table> </li> </ol> </li> <li> <p>Tell Rook to run as old cluster by running <code>kubectl -n rook-ceph edit secret/rook-ceph-mon</code> and changing <code>fsid</code> to the original <code>fsid</code>. Note that the <code>fsid</code> is base64 encoded and must not contain a trailing carriage return. For example:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code>$ <span class=nb>echo</span> -n a811f99a-d865-46b7-8f2c-f94c064e4356 <span class=p>|</span> base64  <span class=c1># Replace with the fsid from your old cluster.</span>
</code></pre></div> </td></tr></table> </li> <li> <p>Disable authentication by running <code>kubectl -n rook-ceph edit cm/rook-config-override</code> and adding content below:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span>
<span class=normal>6</span>
<span class=normal>7</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=nt>data</span><span class=p>:</span><span class=w></span>
<span class=nt>config</span><span class=p>:</span><span class=w> </span><span class="p p-Indicator">|</span><span class=w></span>
<span class=w>    </span><span class=no>[global]</span><span class=w></span>
<span class=w>    </span><span class=no>auth cluster required = none</span><span class=w></span>
<span class=w>    </span><span class=no>auth service required = none</span><span class=w></span>
<span class=w>    </span><span class=no>auth client required = none</span><span class=w></span>
<span class=w>    </span><span class=no>auth supported = none</span><span class=w></span>
</code></pre></div> </td></tr></table> </li> <li> <p>Bring the Rook Ceph operator back online by running <code>kubectl -n rook-ceph edit deploy/rook-ceph-operator</code> and set <code>replicas</code> to <code>1</code>.</p> </li> <li>Watch the operator logs with <code>kubectl -n rook-ceph logs -f rook-ceph-operator-xxxxxxx</code>, and wait until the orchestration has settled.</li> <li><strong>STATE</strong>: Now the new cluster should be up and running with authentication disabled. <code>ceph -s</code> should report 1 mon &amp; 1 mgr &amp; all of the OSDs up and running, and all PGs in either <code>active</code> or <code>degraded</code> state.</li> <li> <p>Run <code>kubectl -n rook-ceph exec -it rook-ceph-tools-XXXXXXX bash</code> to enter tools pod:</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span></pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=go>vi key</span>
<span class=gp># </span><span class=o>[</span>paste keyring content saved before, preserving only <span class=sb>`</span><span class=o>[</span>client admin<span class=o>]</span><span class=sb>`</span> section<span class=o>]</span>
<span class=go>ceph auth import -i key</span>
<span class=go>rm key</span>
</code></pre></div> </td></tr></table> </li> <li> <p>Re-enable authentication by running <code>kubectl -n rook-ceph edit cm/rook-config-override</code> and removing auth configuration added in previous steps.</p> </li> <li>Stop the Rook operator by running <code>kubectl -n rook-ceph edit deploy/rook-ceph-operator</code> and set <code>replicas</code> to <code>0</code>.</li> <li>Shut down entire new cluster by running <code>kubectl -n rook-ceph delete deploy/X</code> where X is every deployment in namespace <code>rook-ceph</code>, except <code>rook-ceph-operator</code> and <code>rook-ceph-tools</code>, again. This time OSD daemons are present and should be removed too.</li> <li>Bring the Rook Ceph operator back online by running <code>kubectl -n rook-ceph edit deploy/rook-ceph-operator</code> and set <code>replicas</code> to <code>1</code>.</li> <li>Watch the operator logs with <code>kubectl -n rook-ceph logs -f rook-ceph-operator-xxxxxxx</code>, and wait until the orchestration has settled.</li> <li><strong>STATE</strong>: Now the new cluster should be up and running with authentication enabled. <code>ceph -s</code> output should not change much comparing to previous steps.</li> </ol> <h2 id=backing-up-and-restoring-a-cluster-based-on-pvcs-into-a-new-kubernetes-cluster>Backing up and restoring a cluster based on PVCs into a new Kubernetes cluster<a class=headerlink href=#backing-up-and-restoring-a-cluster-based-on-pvcs-into-a-new-kubernetes-cluster title="Permanent link">&para;</a></h2> <p>It is possible to migrate/restore an rook/ceph cluster from an existing Kubernetes cluster to a new one without resorting to SSH access or ceph tooling. This allows doing the migration using standard kubernetes resources only. This guide assumes the following<br> 1. You have a CephCluster that uses PVCs to persist mon and osd data. Let's call it the "old cluster"<br> 1. You can restore the PVCs as-is in the new cluster. Usually this is done by taking regular snapshots of the PVC volumes and using a tool that can re-create PVCs from these snapshots in the underlying cloud provider. Velero is one such tool. (<a href=https://github.com/vmware-tanzu/velero>https://github.com/vmware-tanzu/velero</a>)<br> 1. You have regular backups of the secrets and configmaps in the rook-ceph namespace. Velero provides this functionality too.</p> <p>Do the following in the new cluster:<br> 1. Stop the rook operator by scaling the deployment <code>rook-ceph-operator</code> down to zero: <code>kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas 0</code><br> and deleting the other deployments. An example command to do this is <code>k -n rook-ceph delete deployment -l operator!=rook</code><br> 1. Restore the rook PVCs to the new cluster.<br> 1. Copy the keyring and fsid secrets from the old cluster: <code>rook-ceph-mgr-a-keyring</code>, <code>rook-ceph-mon</code>, <code>rook-ceph-mons-keyring</code>, <code>rook-ceph-osd-0-keyring</code>, ...<br> 1. Delete mon services and copy them from the old cluster: <code>rook-ceph-mon-a</code>, <code>rook-ceph-mon-b</code>, ... Note that simply re-applying won't work because the goal here is to restore the <code>clusterIP</code> in each service and this field is immutable in <code>Service</code> resources.<br> 1. Copy the endpoints configmap from the old cluster: <code>rook-ceph-mon-endpoints</code><br> 1. Scale the rook operator up again : <code>kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas 1</code><br> 1. Wait until the reconciliation is over.</p> </article> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> </div> </div> <a href=# class="md-top md-top--hidden md-icon" data-md-component=top> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg> Back to top </a> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../ceph-dashboard/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Ceph Dashboard" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Ceph Dashboard </div> </div> </a> <a href=../ceph-examples/ class="md-footer__link md-footer__link--next" aria-label="Next: Examples" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Examples </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> <a href=/ class=logo> <img src=/images/rook-logo-small.svg alt=rook.io> </a> <p> &#169; Rook Authors {{ site.time | date: '%Y' }}. Documentation distributed under <a href=https://creativecommons.org/licenses/by/4.0>CC-BY-4.0</a>. </p> <p> &#169; {{ site.time | date: '%Y' }} The Linux Foundation. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage/ >Trademark Usage</a> page. </p> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs Insiders </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["content.tabs.link", "instant", "navigation.expand", "navigation.top", "navigation.tracking", "privacy", "search.highlight", "search.share", "search.suggest", "tabs"], "search": "../assets/javascripts/workers/search.5c9dbbf3.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src=../assets/javascripts/bundle.10bf1588.min.js></script> </body> </html>